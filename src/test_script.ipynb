{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FLIR RGB images:  10319\n",
      "Number of FLIR Thermal images:  10742\n",
      "Number of LLVIP RGB images:  12025\n",
      "Number of LLVIP Thermal images:  12025\n",
      "Loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "Creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Base imports\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "# Custom imports\n",
    "from model import InfusionNet\n",
    "import tools.dct as dct_tools\n",
    "from tools.plot_dct import plot_dct, plot_bbox\n",
    "\n",
    "flir_path = '../data/FLIR/'\n",
    "llvip_path = '../data/LLVIP/'\n",
    "\n",
    "flir_rgbimages = os.listdir(flir_path + 'images_rgb_train/data')\n",
    "flir_thermalimages = os.listdir(flir_path + 'images_thermal_train/data')\n",
    "llvip_rgbimages = os.listdir(llvip_path + 'visible/train')\n",
    "\n",
    "llvip_thermalimages = os.listdir(llvip_path + 'infrared/train')\n",
    "\n",
    "print('Number of FLIR RGB images: ', len(flir_rgbimages))\n",
    "print('Number of FLIR Thermal images: ', len(flir_thermalimages))\n",
    "\n",
    "print('Number of LLVIP RGB images: ', len(llvip_rgbimages))\n",
    "print('Number of LLVIP Thermal images: ', len(llvip_thermalimages))\n",
    "\n",
    "llvip = COCO(llvip_path + 'LLVIP.json') # load the dataset\n",
    "llvip_ids = llvip.getImgIds()\n",
    "img_obj = llvip.loadImgs([llvip_ids[1]])\n",
    "anns_obj = llvip.loadAnns(llvip.getAnnIds(imgIds=[llvip_ids[1]]))\n",
    "\n",
    "\n",
    "rgb_img = Image.open(llvip_path + 'visible/train/' + img_obj[0]['file_name'])\n",
    "ir_img = Image.open(llvip_path + 'infrared/train/' + img_obj[0]['file_name'])\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(20,20))\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.imshow(rgb_img)\n",
    "# draw bounding boxes\n",
    "#plot_bbox(rgb_img, anns_obj)\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.imshow(ir_img)\n",
    "# draw bounding boxes\n",
    "#plot_bbox(ir_img, anns_obj)\n",
    "#plt.show()\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "rgb_tensor = transforms(rgb_img).unsqueeze(0)\n",
    "dct_tensor = dct_tools.dct_2d(rgb_tensor, norm='ortho')\n",
    "masked_tensor = dct_tools.mask_image(dct_tensor, 0.1)\n",
    "masked_rgb = dct_tools.idct_2d(masked_tensor, norm='ortho')\n",
    "\n",
    "#plot_dct(rgb_tensor, masked_tensor, masked_rgb)\n",
    "#plot_bbox(rgb_tensor, anns_obj)\n",
    "\n",
    "ir_tensor = transforms(ir_img).unsqueeze(0)\n",
    "\n",
    "dct_tensor = dct_tools.dct_2d(ir_tensor, norm='ortho')\n",
    "\n",
    "masked_tensor = dct_tools.mask_image(dct_tensor, 0.05)\n",
    "\n",
    "masked_ir = dct_tools.idct_2d(masked_tensor, norm='ortho')\n",
    "\n",
    "#plot_dct(ir_tensor, masked_tensor, masked_ir)\n",
    "#plot_bbox(ir_tensor, anns_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 0\n",
      "Input to phase 0: torch.Size([2, 3, 1024, 1280])\n",
      "Input to phase 0: torch.Size([2, 3, 1024, 1280])\n",
      "Phase 1\n",
      "Input shape to inner phases: torch.Size([2, 1, 507, 635])\n",
      "torch.Size([2, 16, 507, 635]) torch.Size([2, 16, 507, 635])\n",
      "Input shape to inner phases: torch.Size([2, 1, 507, 635])\n",
      "torch.Size([2, 16, 507, 635]) torch.Size([2, 16, 507, 635])\n",
      "Phase 2\n",
      "Input shape to inner phases: torch.Size([2, 1, 507, 635])\n",
      "torch.Size([2, 16, 507, 635]) torch.Size([2, 16, 507, 635])\n",
      "Input shape to inner phases: torch.Size([2, 1, 507, 635])\n",
      "torch.Size([2, 16, 507, 635]) torch.Size([2, 16, 507, 635])\n",
      "Phase 3\n",
      "Input shape to inner phases: torch.Size([2, 1, 507, 635])\n",
      "torch.Size([2, 16, 507, 635]) torch.Size([2, 16, 507, 635])\n",
      "Input shape to inner phases: torch.Size([2, 1, 507, 635])\n",
      "torch.Size([2, 16, 507, 635]) torch.Size([2, 16, 507, 635])\n",
      "Output phase 3: torch.Size([2, 1, 507, 635]) torch.Size([2, 1, 507, 635])\n",
      "torch.Size([2, 3, 507, 635])\n"
     ]
    }
   ],
   "source": [
    "from model import InfusionNet\n",
    "import torch\n",
    "infusion_model = InfusionNet(num_features=16, reduction=8, tau = 0.2)\n",
    "#\n",
    "input_tensors = torch.cat((torch.cat((rgb_tensor, ir_tensor), dim=1),torch.cat((rgb_tensor, ir_tensor), dim=1)), dim=0)\n",
    "#\n",
    "output_tensor = infusion_model(input_tensors)\n",
    "#\n",
    "print(output_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
